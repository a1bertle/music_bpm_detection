BPM DETECTION PIPELINE -- FULL OVERVIEW
=========================================

This tool takes an MP3 file, detects its tempo, and outputs a WAV file with
a metronome click track mixed in at the detected beat positions. The pipeline
has six stages, each feeding into the next.


THE FULL PIPELINE
-----------------

    song.mp3
        |
        |  STEP 1: MP3 DECODER
        |  Decompress MP3 into raw float audio samples.
        |  Output: stereo AudioBuffer (L/R interleaved floats)
        |
        v
    Stereo audio -------.  (kept for step 5)
        |               |
        |  to_mono()    |
        v               |
    Mono audio          |
        |               |
        |  STEP 2: ONSET DETECTOR
        |  Find where rhythmic events occur.
        |  Chop into frames, FFT, mel filterbank, spectral flux.
        |  Output: onset strength O[n], one value per frame
        |               |
        v               |
    O[n]                |
        |               |
        |  STEP 3: TEMPO ESTIMATOR
        |  Measure the dominant periodicity.
        |  Autocorrelation + tempo prior + octave correction.
        |  Output: BPM (e.g. 128.2) and period in frames (e.g. 40)
        |               |
        v               |
    BPM + period        |
        |               |
        |  STEP 4: BEAT TRACKER
        |  Place exact beat positions using dynamic programming.
        |  Balance onset alignment with inter-beat regularity.
        |  Output: list of beat sample positions
        |               |
        v               |
    Beat positions      |
        |               |
        |  STEP 5: METRONOME OVERLAY
        |  Synthesize a click and mix it into the stereo audio
        |  at every beat position. Clamp to [-1, 1].
        |               |
        v <-------------'
    Stereo audio with clicks
        |
        |  STEP 6: WAV WRITER
        |  Write 44-byte RIFF header + 16-bit PCM samples.
        |  Output: playable WAV file
        |
        v
    output.wav


--------------------------------------------------------------------------------


STEP 1: MP3 DECODER
---------------------

    Input:   song.mp3 (compressed, ~4 MB)
    Output:  AudioBuffer with float samples, sample rate, channel count

What it does:

    The minimp3 library reverses MP3 compression: Huffman decoding, inverse
    quantization, inverse MDCT, and polyphase synthesis filtering. The result
    is raw PCM audio -- a flat array of float values in [-1.0, +1.0].

    For stereo files, samples are interleaved: L0 R0 L1 R1 L2 R2 ...

    The stereo buffer is kept for step 5 (metronome overlay). A mono copy
    is made by averaging L and R at each frame, and passed to step 2.

Key numbers:

    3-min song at 44.1 kHz stereo = ~16 million floats = ~60 MB in memory.

See: MP3_DECODER_EXPLAINED.txt


--------------------------------------------------------------------------------


STEP 2: ONSET DETECTOR
------------------------

    Input:   mono audio samples
    Output:  onset strength function O[n], one value per frame (~86 fps)

What it does:

    1. Frame the audio into overlapping chunks (2048 samples, 512 hop).
    2. Apply a Hann window to each frame (taper edges to prevent spectral
       leakage in the FFT).
    3. Compute the real-to-complex FFT --> 1025 frequency bins.
    4. Compute the power spectrum: |X[k]|^2 (discard phase).
    5. Apply a 40-band mel filterbank (30-8000 Hz) to compress 1025 bins
       into 40 perceptually-spaced bands.
    6. Log-compress: log10(energy + 1e-10).
    7. Half-wave rectified difference: for each band, keep only energy
       increases between consecutive frames.
    8. Sum across all 40 bands --> one onset strength value per frame.
    9. Normalize to zero mean, unit variance.

Why:

    The mel filterbank lets us detect onsets across different frequency
    ranges independently (a kick drum in the bass doesn't mask a hi-hat
    in the treble). Log compression makes soft onsets visible even during
    loud passages. Half-wave rectification ignores note endings and only
    responds to new sound events.

Key numbers:

    3-min song --> ~15,500 onset frames at 86.13 fps.

See: ONSET_DETECTOR_EXPLAINED.txt


--------------------------------------------------------------------------------


STEP 3: TEMPO ESTIMATOR
-------------------------

    Input:   onset strength O[n]
    Output:  BPM (float) and period_frames (int)

What it does:

    1. Convert the BPM range (50-220) to a lag range in onset frames.
    2. Compute autocorrelation R(lag) for each candidate lag: shift O[n]
       by lag frames and multiply it against itself. Peaks appear where
       the onset pattern repeats.
    3. Normalize R(lag) by overlap count to prevent bias toward longer lags.
    4. Apply a log-Gaussian tempo prior centered at 120 BPM (sigma = 1
       octave on a log2 scale) to bias toward common tempos.
    5. Pick the lag with the highest weighted score.
    6. Octave correction: iteratively try halving the lag. If the half-lag
       has a strong peak (above the median noise floor), prefer it. This
       escapes sub-harmonic traps where 60 BPM wins over 120 BPM.
    7. Parabolic interpolation around the peak for sub-lag BPM precision
       (~0.1 BPM accuracy instead of ~2.7 BPM per integer lag step).

Why:

    Autocorrelation naturally reveals periodicities, but it also peaks at
    integer multiples of the true period (the octave problem). The tempo
    prior and octave correction together resolve this ambiguity. Parabolic
    interpolation overcomes the coarse resolution of integer lag steps.

Key numbers:

    Lag range: ~23 to ~103 frames (80 candidate lags to evaluate).
    Resolution after interpolation: ~0.1 BPM.

See: TEMPO_ESTIMATOR_EXPLAINED.txt


--------------------------------------------------------------------------------


STEP 4: BEAT TRACKER
---------------------

    Input:   onset strength O[n] + estimated period T (in frames)
    Output:  list of beat positions in audio samples

What it does:

    Uses the Ellis 2007 dynamic programming algorithm:

    1. Forward pass: for each frame t, search all valid predecessor frames
       p in the window [t - 2T, t - T/2]. Score each candidate:

           score = dp[p] + O[t] - alpha * (ln((t-p) / T))^2

       This balances three things:
         - dp[p]: how good was the sequence up to the predecessor?
         - O[t]: is there an onset at the current frame? (reward)
         - penalty: how far is the spacing from the expected period? (cost)

       Keep the best predecessor and store it in prev[t].

    2. Backtrace: find the highest-scoring frame in the last 10% of the
       signal. Follow prev[] pointers backward to reconstruct the full
       beat sequence. Reverse to get chronological order.

    3. Convert frame indices to sample positions: frame * hop_size.

Why:

    Simply picking peaks in O[n] fails because there are too many onsets
    (hi-hats, ghost notes) and some beats have weak onsets (rests,
    syncopation). The DP finds the globally optimal sequence -- the one
    that best balances onset alignment with rhythmic regularity across the
    entire track, not just locally.

Key numbers:

    alpha = 680 (regularity strength). Search window = ~3T frames wide.
    A 3-min song at 120 BPM produces ~360 beats.

See: BEAT_TRACKER_EXPLAINED.txt


--------------------------------------------------------------------------------


STEP 5: METRONOME OVERLAY
---------------------------

    Input:   stereo AudioBuffer + beat sample positions
    Output:  stereo AudioBuffer with click sounds mixed in

What it does:

    1. Synthesize a click waveform (done once):
       882 samples of a 1000 Hz sine wave with exponential decay (rate 200).
       Sounds like a short, bright tap.

    2. For each beat position, add the click to both L and R channels at
       that sample offset. Adding to both channels centers the click in
       the stereo field.

    3. Clamp all samples to [-1.0, +1.0] to prevent clipping in loud
       passages where the click pushes the signal over the limit.

Why:

    The click track is how you verify the detection. Play the output file
    and listen: if the clicks land on the beat, the BPM detection worked.
    A decaying sine (rather than a raw impulse) gives a clean, pitched
    tick that cuts through the music without sounding harsh.

Key numbers:

    Click: 1000 Hz, 20 ms, 882 samples. Amplitude default 0.5.

See: METRONOME_EXPLAINED.txt


--------------------------------------------------------------------------------


STEP 6: WAV WRITER
--------------------

    Input:   stereo AudioBuffer (float samples with clicks)
    Output:  output.wav file on disk

What it does:

    1. Write a 44-byte RIFF/WAVE header specifying: PCM format, stereo,
       44100 Hz, 16-bit, and the total data size.

    2. For each float sample:
       - Clamp to [-1.0, +1.0]
       - Multiply by 32767
       - Cast to 16-bit signed integer
       - Write 2 bytes in little-endian order

Why:

    WAV is the simplest lossless audio format -- no compression library
    needed, universally playable, trivial header. The tradeoff is file size
    (~30 MB for a 3-min stereo track vs ~4 MB as MP3), which is fine for
    a diagnostic tool.

Key numbers:

    Header: 44 bytes. 16-bit PCM, -96 dB noise floor.
    File size: ~10 MB per minute of stereo audio.

See: WAV_WRITER_EXPLAINED.txt


--------------------------------------------------------------------------------


DATA FLOW SUMMARY
------------------

Each step transforms data from one representation to the next:

Step  Input                    Transform               Output
----  -----------------------  ----------------------  --------------------------
  1   MP3 bytes                Decompress              Float samples (stereo)
  2   Float samples (mono)     Spectral flux           Onset strength O[n]
  3   O[n]                     Autocorrelation         BPM + period
  4   O[n] + period            Dynamic programming     Beat sample positions
  5   Stereo audio + beats     Mix clicks              Stereo audio with clicks
  6   Stereo audio with clicks Float-to-int16 + write  WAV file on disk


Data sizes for a typical 3-minute stereo song at 44.1 kHz:

Step  Output size
----  ------------------------------------------
  1   ~16 million floats (~60 MB)
  2   ~15,500 floats (~60 KB)        <-- massive compression
  3   2 numbers: BPM + period        <-- just two values!
  4   ~360 integers                  <-- one per beat
  5   ~16 million floats (~60 MB)    <-- back to full audio
  6   ~30 MB WAV file on disk


The pipeline is a funnel: steps 1-3 progressively compress millions of
samples down to a single BPM number, then steps 4-6 expand back out to
a full audio file with beat annotations.


    60 MB          60 KB       2 numbers    360 ints       60 MB        30 MB
  [samples] --> [onsets] --> [BPM+period] --> [beats] --> [audio] --> [WAV file]
      |              |            |              |            |           |
    step 1        step 2       step 3         step 4       step 5      step 6
   decode        detect       estimate        track       overlay      write
